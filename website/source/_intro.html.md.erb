Many of the biggest science applications running today -- from climate models to economic forecasting to quantum chemistry -- are probabilistic simulations. Because the models involved are often too complex, with too many intermediate branches to derive analytically, much of this “big science” relies on Markov Chain Monte Carlo (MCMC) methods (basically, drawing lots of samples and taking averages). This increased complexity, especially probabilistic complexity, is a subtle but challenging consequence of scientific studies and models that involve ever larger datasets.

A specific problem (related to the familiar idea of non-convexity) is multi-modality. When a probabilistic simulation is multi-modal, there isn't a single cluster of likely configurations centered around a characteristic average. Instead, in a multi-modal distribution there are multiple such clusters distributed far away from each other in the model's parameter space. One example where this occurs is topic modeling <%= %>, and also in the problem of localizing sensors based on noisy measurements of inter-sensor distance -- which is commonly used as a benchmark for multi-modal sampling techniques <%= cite 'wormhole' %>, <%= cite 'darting' %>.

